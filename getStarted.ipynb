{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inciando a sessão spark, que pode ser vista como uma manifestação do driver process para o usuário "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo a leitura do arquivo. \n",
    "A leitura de um arquivo, não e uma action dentro do spark, por conta disso, ela será apenas inserida a uma pilha de transformações, que serão todas executadas no momento em que uma action for invocada\n",
    "\n",
    "Interessante saber que, nesse momento meu df, possui um determinado numero de colunas, porém um indeterminado numero de linhas, isso se dá devido a ação de leitura ser executada em lazy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Timestamp: double, Open: double, High: double, Low: double, Close: double, Volume: double]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bitcoin = spark.read.option('inferSchema', 'true'\n",
    "                        ).option('header', 'true'\n",
    "                        ).csv('./data/archive/btcusd_1-min_data.csv')\n",
    "df_bitcoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando a action take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Timestamp=1325412060.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412120.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bitcoin.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----+----+-----+------+\n",
      "|   Timestamp|Open|High| Low|Close|Volume|\n",
      "+------------+----+----+----+-----+------+\n",
      "|1.32541206E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541212E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541218E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541224E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "| 1.3254123E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541236E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541242E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541248E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541254E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "| 1.3254126E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541266E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541272E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541278E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541284E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "| 1.3254129E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541296E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541302E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541308E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "|1.32541314E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "| 1.3254132E9|4.58|4.58|4.58| 4.58|   0.0|\n",
      "+------------+----+----+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bitcoin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo nossa primeira transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, vou realizar uma transformação do tipo sort. \n",
    "Por definição a ordenação de uma linha em relação a outras não pode ser tratada como uma narrow transformation.\n",
    "Uma vez que a ordenação depende das outras linhas, por conta idsso trata-se de uma wide transformations. (quando o processamento é feito em disco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [Timestamp#42 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(Timestamp#42 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=85]\n",
      "      +- FileScan csv [Timestamp#42,Open#43,High#44,Low#45,Close#46,Volume#47] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/a:/DS/Spark/learningSpark/data/archive/btcusd_1-min_data.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Timestamp:double,Open:double,High:double,Low:double,Close:double,Volume:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bitcoin.sort('Timestamp').explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternado a configuração do spark, para retornar 5 arquivos de particao como saida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions', '5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Timestamp=None, Open=57854.0, High=57864.0, Low=57835.0, Close=57835.0, Volume=1.35346619),\n",
       " Row(Timestamp=1325412060.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412120.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412180.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412240.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412300.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412360.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0),\n",
       " Row(Timestamp=1325412420.0, Open=4.58, High=4.58, Low=4.58, Close=4.58, Volume=0.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bitcoin.sort('Timestamp').take(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
